{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb1eb4d-5cb5-4bce-910c-764a7655c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Initialize counters for excluded days\n",
    "excluded_days_due_to_points = 0\n",
    "excluded_days_due_to_minutes = 0\n",
    "\n",
    "# Initialize lists to collect outlier statistics and cleaned dataframes\n",
    "outlier_stats = []\n",
    "cleaned_dataframes = []\n",
    "\n",
    "def detect_gaps(df, gap_threshold=30, pre_gap_buffer=60, post_gap_buffer=60, start_of_day=0, end_of_day=1440):\n",
    "    df = df.sort_values(by='time_of_day').reset_index(drop=True)\n",
    "    time_diffs = df['time_of_day'].diff().fillna(0)\n",
    "    gap_indices = time_diffs[time_diffs > gap_threshold].index\n",
    "    df['near_gap'] = False\n",
    "    df['pre_gap'] = False\n",
    "    df['post_gap'] = False\n",
    "\n",
    "    # Flagging the start of the day if it starts late\n",
    "    if df['time_of_day'].iloc[0] > start_of_day + post_gap_buffer:\n",
    "        df.loc[0, 'post_gap'] = True\n",
    "        buffer_indices = df[df['time_of_day'] <= df['time_of_day'].iloc[0] + post_gap_buffer].index\n",
    "        df.loc[buffer_indices, 'post_gap'] = True\n",
    "\n",
    "    for idx in gap_indices:\n",
    "        immediate_range = range(max(0, idx - 1), min(len(df), idx + 2))\n",
    "        df.loc[immediate_range, 'near_gap'] = True\n",
    "        \n",
    "        # Pre-gap buffer zone\n",
    "        pre_gap_start = max(0, idx - pre_gap_buffer)\n",
    "        df.loc[pre_gap_start:idx, 'pre_gap'] = True\n",
    "        \n",
    "        # Post-gap buffer zone\n",
    "        post_gap_end = min(len(df), idx + post_gap_buffer)\n",
    "        df.loc[idx:post_gap_end, 'post_gap'] = True\n",
    "\n",
    "    # Flagging the end of the day if it ends early\n",
    "    if df['time_of_day'].iloc[-1] < end_of_day - pre_gap_buffer:\n",
    "        df.loc[len(df) - 1, 'pre_gap'] = True\n",
    "        buffer_indices = df[df['time_of_day'] >= df['time_of_day'].iloc[-1] - pre_gap_buffer].index\n",
    "        df.loc[buffer_indices, 'pre_gap'] = True\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def process_date(df, specific_date, min_hours=3, min_points=300, gap_threshold=30, min_minutediff_threshold=0):\n",
    "    global excluded_days_due_to_points, excluded_days_due_to_minutes\n",
    "    df = df[df['date.1'] == specific_date].reset_index(drop=True)\n",
    "\n",
    "    if df.shape[0] < min_points:\n",
    "        print(f\"Skipping {specific_date}: Not enough data points ({df.shape[0]})\")\n",
    "        excluded_days_due_to_points += 1\n",
    "        return\n",
    "    \n",
    "    unique_minutes = df['time_of_day'] // 1\n",
    "    if unique_minutes.nunique() < 180:\n",
    "        print(f\"Skipping {specific_date}: Not enough data minutes ({unique_minutes.nunique()})\")\n",
    "        excluded_days_due_to_minutes += 1\n",
    "        return\n",
    "\n",
    "    df = df[df['travel_time_minute'] > min_minutediff_threshold].reset_index(drop=True)\n",
    "    df = detect_gaps(df, gap_threshold)\n",
    "    \n",
    "    # Apply LOWESS\n",
    "    frac = 0.15  # Adjust this based on your data visualization and requirements\n",
    "    it = 3      # Default is typically fine; adjust if necessary\n",
    "    delta = 1.2 # Default; consider adjusting for large data\n",
    "    lowess_smoothed = lowess(df['travel_time_minute'], df['time_of_day'], frac=frac, it=it, delta=delta)\n",
    "    lowess_x, lowess_y = lowess_smoothed[:, 0], lowess_smoothed[:, 1]\n",
    "\n",
    "    df['predicted'] = np.interp(df['time_of_day'], lowess_x, lowess_y)\n",
    "    df['residual'] = df['travel_time_minute'] - df['predicted']\n",
    "        # Calculate statistical metrics\n",
    "    std = np.std(df['residual'])\n",
    "    q75, q25 = np.percentile(df['residual'], [75 ,25])\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    # Histogram of residuals\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df['residual'], bins=30, color='gray', alpha=0.6, label='Residuals Distribution')\n",
    "    plt.axvline(x=3 * std, color='r', linestyle='--', linewidth=2, label='Â±3 STD')\n",
    "    plt.axvline(x=-3 * std, color='r', linestyle='--', linewidth=2)\n",
    "    plt.axvline(x=1.5 * iqr + q75, color='b', linestyle='--', linewidth=2, label='1.5 IQR upper')\n",
    "    plt.axvline(x=q25 - 1.5 * iqr, color='b', linestyle='--', linewidth=2, label='1.5 IQR lower')\n",
    "    plt.title(f'Residuals Distribution on {specific_date}')\n",
    "    plt.xlabel('Residual Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    slopes = np.gradient(lowess_y, lowess_x)\n",
    "    df['high_slope'] = np.abs(slopes) > 0.5\n",
    "    \n",
    "    df['high_slope_near_gap'] = False\n",
    "    df['high_slope_not_near_gap'] = False\n",
    "    for idx in df.index[df['high_slope']]:\n",
    "        range_indices = range(max(0, idx - 10), min(len(df), idx + 11))\n",
    "        df.loc[range_indices, 'high_slope_near_gap'] = df.loc[range_indices, 'near_gap']\n",
    "        df.loc[range_indices, 'high_slope_not_near_gap'] = ~df.loc[range_indices, 'near_gap']\n",
    "\n",
    "    # Filter out the residuals that are significant outliers\n",
    "\n",
    "    significant_residuals = (df['residual'].abs() > 3 * np.std(df['residual'])) | (df['residual'].abs() < -1 * np.std(df['residual']))\n",
    "    df_filtered = df[~significant_residuals].reset_index(drop=True)\n",
    "    \n",
    "    # Parameters for Isolation Forest\n",
    "    n_estimators = 100  # Number of base estimators in the ensemble\n",
    "    max_samples = 'auto'  # Number of samples to draw from X to train each base estimator\n",
    "    contamination = 0.01  # The proportion of outliers in the data set\n",
    "    max_features = 1.0  # Number of features to draw from X to train each base estimator\n",
    "    bootstrap = True  # If True, individual trees are fit on random subsets of the dataset sampled with replacement\n",
    "    random_state = 42  # Ensures reproducibility of the results\n",
    "\n",
    "    # Create the Isolation Forest instance\n",
    "    iforest = IsolationForest(\n",
    "        n_estimators=n_estimators,\n",
    "        max_samples=max_samples,\n",
    "        contamination=contamination,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1  # Utilize all processors for parallel processing\n",
    "    )\n",
    "    \n",
    "    iforest_scores = iforest.fit_predict(df_filtered[['travel_time_minute']].values.reshape(-1, 1))\n",
    "    df_filtered['iforest_score'] = iforest_scores\n",
    "    \n",
    "    df_filtered['ISO_slope_near'] = (df_filtered['iforest_score'] == -1) & df_filtered['high_slope_near_gap'] & (df_filtered['travel_time_minute']>30)\n",
    "    df_filtered['ISO_slope_non_near'] = (df_filtered['iforest_score'] == -1) & df_filtered['high_slope_not_near_gap']  & (df_filtered['travel_time_minute']>30)\n",
    "    df_filtered['ISO_slope_pre_gap'] = (df_filtered['iforest_score'] == -1) & df_filtered['pre_gap']  & (df_filtered['travel_time_minute']>30)\n",
    "    df_filtered['ISO_slope_post_gap'] = (df_filtered['iforest_score'] == -1) & df_filtered['post_gap']  & (df_filtered['travel_time_minute']>30)\n",
    "    df_filtered['ISO_slope_near_gap'] = (df_filtered['iforest_score'] == -1) & df_filtered['near_gap']  & (df_filtered['travel_time_minute']>30)\n",
    "    \n",
    "    outlier_stats.append({\n",
    "        'date': specific_date,\n",
    "        'total_points': len(df_filtered),\n",
    "        'lowess_outliers': np.sum(significant_residuals),\n",
    "        'ISO_slope_near': np.sum(df_filtered['ISO_slope_near']),\n",
    "        'ISO_slope_non_near': np.sum(df_filtered['ISO_slope_non_near'])\n",
    "    })\n",
    "    \n",
    "    # Combine all gap-related conditions into a single Boolean Series\n",
    "    near_gap_conditions = (\n",
    "        df_filtered['ISO_slope_near'] | \n",
    "        df_filtered['ISO_slope_non_near'] | \n",
    "        df_filtered['ISO_slope_pre_gap'] | \n",
    "        df_filtered['ISO_slope_post_gap'] | \n",
    "        df_filtered['ISO_slope_near_gap']\n",
    "    )\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.scatter(df['time_of_day'], df['travel_time_minute'], alpha=0.3, label='Data Points', c='grey')\n",
    "    plt.plot(lowess_x, lowess_y, color='blue', label='LOWESS Fit', linewidth=2)\n",
    "    plt.scatter(df['time_of_day'][significant_residuals], df['travel_time_minute'][significant_residuals], color='red', edgecolor='k', s=50, label='LOWESS Outliers')\n",
    "    plt.scatter(\n",
    "        df_filtered['time_of_day'][near_gap_conditions], \n",
    "        df_filtered['travel_time_minute'][near_gap_conditions],\n",
    "        color='purple',  # Choose a color that signifies all 'near gap' points\n",
    "        edgecolor='k', \n",
    "        s=50, \n",
    "        label='ISO-Near Gap'  # Unified label\n",
    "    )\n",
    "    \n",
    "    plt.xlabel('Time of Day (minutes from 0 to 1440)', fontsize=14)\n",
    "    plt.ylabel('Travel Time (minutes)', fontsize=14)\n",
    "    plt.xticks(range(0, 1441, 60), fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.title(f'Travel Time vs Time of Day on {specific_date}', fontsize=16)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    condition = (\n",
    "        df_filtered['ISO_slope_near'] | df_filtered['ISO_slope_non_near'] |\n",
    "        df_filtered['ISO_slope_pre_gap'] | df_filtered['ISO_slope_post_gap'] |\n",
    "        df_filtered['ISO_slope_near_gap']\n",
    "    )\n",
    "    df_filtered = df_filtered[~condition].reset_index(drop=True)\n",
    "    \n",
    "    cleaned_dataframes.append(df_filtered)    \n",
    "\n",
    "def save_cleaned_data(filename='your_dataset.csv'):\n",
    "    # Concatenate all cleaned dataframes\n",
    "    all_cleaned_data = pd.concat(cleaned_dataframes)\n",
    "    # Save to CSV\n",
    "    all_cleaned_data.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Assuming 'df' is your DataFrame and is already loaded\n",
    "unique_dates = df['date.1'].unique()\n",
    "for specific_date in unique_dates:\n",
    "    process_date(df, specific_date, min_hours=3, min_points=300, gap_threshold=30)\n",
    "\n",
    "save_cleaned_data('your_dataset.csv')  # Save the cleaned data to a CSV file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
